# 1. 물리적 데이터 설계

### 1. 보조 기억 장치

- 사용자가 원하는 데이터를 검색하기 위해서 DBMS는 디스크 상의 DB로부터 사용자가 원하는 데이터를 포함하고 있는 **block**을 읽어 주 기억 장치로 가져온다
- 주 기억 장치에서 변경된 block의 경우 다시 디스크에 write한다
- block의 전형적인 크기는 4096 byte (4kb)
- 각 파일(relation)은 고정된 크기의 block으로 나누어 저장된다
- 디스크는 DB를 장기간 보관하는 주된 보조 기억 장치

### 2. 자기 디스크

- 디스크는 자기 물질로 이루어진 여러 개의 판으로 이루어져 있다
- 각 면마다 디스크 헤드가 존재
- 각 판은 트랙과 섹터로 구분
    - 트랙: 정보는 디스크 표면 상의 동심원(트랙)을 따라 저장
    - 실린더: 여러 개의 디스크 면 중 같은 지름을 갖는 트랙들
        - 한 릴레이션을 한 실린더 내에 위치를 시키면, 헤더가 움직일 필요가 없기 때문에 아주 효율적이 될 수 있다 (seek time)
    - 블록은 한 개 이상의 섹터로 이루어져 있다
    - i/o 작업에 걸리는 시간 seek time, rotational delay, transfer time

### 3. 버퍼 관리와 운영 체제

- 디스크 입출력은 컴퓨터 시스템에서 가장 속도가 느린 작업이기 때문에 입출력 횟수를 줄이는 것이 DBMS 성능 향상에 중요
    - 가능하면 많은 블록을 주 기억 장치에 유지하거나, 자주 참조되는 블록들을 주 기억 장치에 유지하면 블록 전송 횟수를 줄일 수 있다
    - **버퍼**는 디스크 블록을 저장하는데 사용되는 주 기억 공간
- Fill Factor
    - 각 블록에 레코드를 채우는 공간의 비율
    - 나중에 레코드가 삽입될 때 기존의 레코드를 이동하는 가능성을 줄이기 위해, 어느 정도 공간을 비워 놓는다
- BLOB (Binary Large Object)
    - 이미지(GIF, JPG), 동영상(MPEG, AVI) 등 대규모 크기 데이터를 저장하는데 사용
    - BLOB은 MS SQL에서 최대 2GB까지도 가능

### 5. 디스크 상에서 파일의 레코드 배치

1. 고정 길이 레코드
    1. 삭제 시 여러 개의 레코드를 이동해서 빈 자리 채우기
    2. 삭제 시 맨 마지막 레코드 하나를 이동해서 빈 자리 채우기
2. 가변 길이 레코드
    1. 가변 길이 레코드에서는 고정 길이 레코드와 달리 이동 불가
    2. 레코드의 길이가 다르기 때문
    
3. **clustering** : 함께 검색될 가능성이 높은 레코드를 디스크 내에서 **물리적으로 연속되게 저장하는 것**
    1. 파일 내 클러스터링 (intra-file clustering)
    2. inter-file clustering
        
        : 함께 검색될 가능성이 높은 두 개 이상의 파일에 속한 레코드들을 물리적으로 가까운 곳에 저장하는 것
        

### 6. 파일 조직

1. **heap file** 
    1. 가장 단순한 파일 조직
    2. 레코드가 삽입된 순서대로 파일에 저장
        1. 삽입 : 파일의 가장 끝에 첨부된다 (append)
        2. 검색 : 원하는 레코드를 찾기 위해 순차적으로 접근
        3. 삭제 : 원하는 레코드를 찾은 후에 그 레코드를 삭제하고, 삭제된 레코드가 차지하던 공간을 다시 사용하지 않는다.
    3. 삽입에는 빠르나 검색과 삭제에서 오래 걸린다.
    → 그래서 heap file은 특수한 경우 외에는 사용하지 않는다.
    4. 삭제가 많다면 공간 낭비가 크기 때문에, 좋은 성능을 유지하기 위해 주기적으로 재조직할 필요성 존재
2. **sequential file**
    1. 특정한 attribute 값 기준으로 sorting 해서 저장한 파일
    2. 보통 search key (탐색에 많이 사용되는 key) 값을 기준으로 정렬
        1. 삽입 : 삽입하려는 레코드 순서를 고려해야 하기 때문에 시간이 많이 걸린다
        2. 삭제: heap file과 동일
    3. search key를 기준으로 찾는다면 binary search (O logN)으로 찾기 가능
        
        search key를 기준으로 찾는 경우가 아니라면 heap file과 마찬가지로 순차 탐색
        
    4. search key를 기준으로 찾는 탐색만 빠르고, 삽입, 삭제, search key가 아닌 탐색에는 느리다.
3. 위의 두 가지는 이론적으로 나온 초창기 방식
4. 실제로는 index 기반으로 파일 관리
    1. 단일 단계 인덱스
    2. 다단계 인덱스
    

### 7. 단일 단계 인덱스

- 파일에 별도의 인덱스 파일을 하나만 만들어 관리
- 인덱스에 저장되는 내용 (엔트리)
    - **search key**
        - 인덱스의 기준이 될 attribute = 인덱스가 정의된 필드
        - 탐색 키의 값은 각 tuple마다 반드시 고유할 필요는 없다
        - 인덱스는 탐색 키를 기준으로 오름차순 저장되기 때문에 binary search 사용 가능
    - **pointer** : 모든 레코드에 대한 주소 (4 byte)
- 인덱스의 크기는 데이터 파일에 비해 훨씬 작다
- 한 파일에 필요한 경우 여러 index를 생성 가능

- **primary index** (기본 인덱스)
    - primary key를 기준으로 만든 인덱스
    - primary index는 흔히 희소 인덱스로 유지될 수 있다
    - 모든 레코드가 아니라 대표 값만 추려서 만든 index
    - primary key를 기준으로 sorting되어 있는 파일에 대해서만 primary index를 생성 가능
        
- **clustering index** (클러스터링 인덱스)
    - 탐색 키 값을 기준으로 정렬된 데이터 파일
    - 데이터 자체가 클러스터링 되어 있다는 사실과 같다
    - 어떤 키 값보다 큰 값을 찾는 등의 range query(범위 질의)에 유용
    - 같은 블록 내에 연속적으로 저장하는 인덱스
- **secondary index** (보조 인덱스)
    - 한 relation에서는 primary key 뿐만이 아니라, 다른 attribute로도 index를 생성 가능한데, 이러한 경우가 보조 인덱스
    - 보조 인덱스는 해당 키를 기준으로 sorting 되어 있지 않다
    - 일반적으로 밀집 인덱스이기 때문에 primary key를 통해 access 하는 것보다는 시간이 더 걸린다
    
- 희소 인덱스와 밀집 인덱스의 비교
    - 보통 희소 인덱스가 모든 경우에 좋다
    - count와 같은 query에서 (데이터에 직접 접근할 필요 없이 레코드 수만 계산하는 경우)에는 밀집 인덱스가 더 낫기도 하다
    - 한 파일(relation)은 하나의 희소 인덱스와 다수의 밀집 인덱스를 가질 수 있다
- 클러스터링 인덱스와 보조 인덱스의 비교
    - 클러스터링 인덱스는 희소 인덱스일 경우가 많으며 범위 질의 등에 좋다
    - 보조 인덱스는 밀집 인덱스이기 때문에, 일부 질의에 대해서는 파일에 접근할 필요 없이 처리 가능하다

### 8. 다단계 인덱스

- 단일 단계 인덱스에서는 인덱스 자체가 큰 경우가 많다
    - 인덱스를 탐색하는 시간도 오래 걸린다
    - 그렇기 때문에 인덱스 엔트리 탐색하는 시간을 줄이려는 노력 필요
    - 단일 단계 인덱스를 하나의 순서 파일로 간주하고, 다시 단일 단계 인덱스 위에 인덱스를 정의
    - 다단계 인덱스는 가장 상위 단계의 모든 인덱스 엔트리들이 한 블록에 들어갈 수 있을 때까지 이런 과정을 반복
    - **master index**
        - 가장 상위 단계의 인덱스로 **한 블록**으로 이루어져 있는 인덱스를 의미
        - 한 블록으로 작기 때문에 **주 기억 장치**에 상주 가능
            - 작업이 완료될 때까지 계속 주 기억 장치에 유지
        - 대부분 **B+ 트리**를 사용
- 다단계 인덱스의 기본 형식 (B+ 트리 x)
    
    - 탐색에는 빠르나 insert, delete, update에 따른 유지 보수에 비용이 크다
    - 일종의 트리 형태
        - 알고리즘에 따라 root에서 leaf 노드까지의 길이가 모두 일정하지 않을 가능성이 높을 수 있다 (skewed tree)
        - child의 개수가 모두 다를 수 있다
    - ⇒ **B+ 트리가 나온 이유 (B는 balanced)**
        - **root부터 leaf까지 모든 경우에 depth가 일정**
        - **모든 노드 간의 child 개수를 일정하게 유지**
        
- SQL에서의 index 정의문
    - create table에서 primary key로 지정한 필드에 자동으로 기본 인덱스 생성
    - unique로 명시한 attribute에 대해서는 자동적으로 보조 인덱스 형성
    - 나머지 attribute에 추가로 index를 정의하기 위해서는 별도로 지정 필요
    - (e.g.) CREATE INDEX 인덱스명 ON 테이블 (칼럼1, 칼럼2, …);
    - range query에서도 활용 가능

- 인덱스의 장점과 단점
    - 검색 속도 향상
    - 소수의 레코드를 수정, 삭제하는 연산
    - 인덱스를 저장하기 위한 공간이 필요
    - 삽입, 삭제, 수정 연산 속도는 저하
    - relation이 매우 크고, 질의에서 relation **튜플 중 일부 (예 2-4%)**를 검색하고, where 절이 잘 표현되었을 때 특히 성능에 도움된다 → 대량 파일에서 소량의 데이터를 검색하는 경우
- 인덱스 선정 지침과 데이터베이스 튜닝
    - 가장 중요한 질의와 이들의 수행 빈도
    - 가장 중요한 갱신과 이들의 수행 빈도
    - = workload
    - 워크로드를 잘 선별해야 하고, where 조건에 어떤 attribute들이 선택되는지, 이 조건들의 선별력은 어느 정도인지
    
    
- 인덱스가 사용되지 않는 때
    - 인덱스가 정의된 애트리뷰트에 산술 연산자 사용
    - DBMS가 제공하는 내장 함수가 집단 함수 대신에 사용되는 경우
    - relation 크기가 작은 경우
    - 시스템 카탈로그가 오래 전의 데이터베이스 상태를 나타낼 때 (최신 정보가 아닐 때)


### 9. B+ Tree

- 최대 child 크기는 key 크기에 따라 결정 + child 크기의 50% 이상은 채워야 한다
- 위의 규칙을 지키면서 노드들을 합치고 분리하는 과정을 반복


# 2. Relation Normalization

1. 릴레이션 정규화
    1. 데이터베이스를 만드는 목적: 중복을 최소화
    2. 가급적이면 key값만 여러 relation에 걸쳐 중복해서 가지려 한다
    3. 부주의한 데이터베이스 설계는 여러 갱신 이상(update anomaly)를 발생
    4. 정규화(normalization)은 주어진 릴레이션 스키마를 함수적 종속성과 기본 키 기반으로 분석하여, 중복과 갱신 이상을 최소화
2. 갱신 이상
    1. 수정 인상(modification anomaly) : 반복된 데이터 중 일부만 수정하여 데이터 불일치 발생
    2. 삽입 이상 (insertion anomaly) : 불필요한 정보를 함께 저장하지 않고는 어떤 정보를 저장하는 것이 불가능
    3. 삭제 이상 (deletion anomaly) : 유용한 정보를 함께 삭제하지 않고는 어떤 정보를 삭제하는 것이 불가능